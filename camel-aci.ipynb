{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "872981be",
   "metadata": {},
   "source": [
    "# CAMEL Cookbook - Object Detection with ACI.dev MCP Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c98d9",
   "metadata": {},
   "source": [
    "**Description:** Learn how to build an object detection agent using CAMEL AI and ACI.dev's MCP protocol for seamless ML tasks. \n",
    "\n",
    "‚≠ê Star us on [GitHub](https://github.com/camel-ai/camel), join our [Discord](https://discord.gg/EXAMPLE), or follow us on [X](https://x.com/camelaiorg)\n",
    "\n",
    "This cookbook shows how to build a powerful object detection agent using CAMEL AI connected to ACI.dev's MCP tools. We'll create an agent that analyzes images, detects objects like cars or trees, and explains results in natural language‚Äîall without writing complex ML code.\n",
    "\n",
    "**Key Learnings:**\n",
    "- Why agents need tools to be truly useful.\n",
    "- How MCP enables dynamic, aware tool usage for tasks like object detection.\n",
    "- Setting up CAMEL with ACI.dev for real-time image analysis.\n",
    "- Building and running your own object detection agent.\n",
    "- Handling outputs with summaries, tables, and visualized results.\n",
    "\n",
    "This setup uses CAMEL's `MCPToolkit` to connect to ACI.dev's MCP servers, powering object detection via Replicate's ML models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad4834",
   "metadata": {},
   "source": [
    "### üì¶ Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install camel-ai aci-mcp aci-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e21e0",
   "metadata": {},
   "source": [
    "Set up keys (ACI_API_KEY, LINKED_ACCOUNT_OWNER_ID, GOOGLE_API_KEY, REPLICATE_API_TOKEN) in `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e484b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf512d1",
   "metadata": {},
   "source": [
    "### Define CAMEL agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df8125d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = \"ObjectDetectionAgent\"\n",
    "system_prompt=\"\"\"\n",
    "You are a specialized Object Detection Agent. Your primary function is to use the `REPLICATE.run` tool for object detection and present the findings in a user-friendly format. \"\n",
    "\"The user will provide a text prompt containing an image URL and a query. You must extract the `image` URL and the `query` object(s). \"\n",
    "\"Immediately call the `REPLICATE.run` tool. The `input` must be a dictionary with two keys: `image` (the URL) and `query` (a string of the object(s)). \"\n",
    "\"Do not ask for clarification; make a reasonable inference if the query is ambiguous. \"\n",
    "\"After receiving the tool's output, format your response as follows: \"\n",
    "\"- **Natural Language Summary:** Start with a detailed friendly, insightful analysis of the detection results in plain English. \"\n",
    "\"- **Markdown Table:** Create a markdown table with columns: 'Object', 'Confidence Score', and 'Bounding Box Coordinates'. \"\n",
    "\"- **Result Image:** If the tool provides a URL for an image with bounding boxes, display it using markdown: `![Detected Objects](URL_HERE)`. \"\n",
    "\"Whenever I give you a link, trigger the tool call, extract its outputs and links, and present me in a proper markdown format with detailed analysis from the tool call in natural language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de159dc",
   "metadata": {},
   "source": [
    "### MCP servers configuration using ACI.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b360b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<camel.toolkits.mcp_toolkit.MCPToolkit at 0x109104f70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from camel.toolkits import MCPToolkit\n",
    "mcp_config = {\n",
    "    \"mcpServers\": {\n",
    "        \"aci_apps\": {\n",
    "            \"command\": \"aci-mcp\",\n",
    "            \"args\": [\n",
    "                \"apps-server\",\n",
    "                \"--apps=REPLICATE\",\n",
    "                \"--linked-account-owner-id\",\n",
    "                \"parthshr370\"\n",
    "            ],\n",
    "            \"env\": {\"ACI_API_KEY\": os.getenv(\"ACI_API_KEY\")},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "mcp_toolkit = MCPToolkit(config_dict=mcp_config)\n",
    "await mcp_toolkit.connect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f65a18",
   "metadata": {},
   "source": [
    "Define the CAMEL agent with GEMINI 2.5 Flash model with Replicate MCP tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "834b52ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.agents import ChatAgent\n",
    "from camel.messages import BaseMessage\n",
    "from camel.models import ModelFactory\n",
    "from camel.types import ModelPlatformType\n",
    "\n",
    "tools = mcp_toolkit.get_tools()\n",
    "\n",
    "# Initialize Gemini model\n",
    "model = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.GEMINI,\n",
    "    model_type=\"gemini-2.5-flash\",\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    model_config_dict={\"temperature\": 0.0, \"max_tokens\": 4096},\n",
    ")\n",
    "\n",
    "# Create system message\n",
    "sys_msg = BaseMessage.make_assistant_message(\n",
    "    role_name=agent_name,\n",
    "    content=system_prompt,\n",
    ")\n",
    "\n",
    "agent = ChatAgent(model=model, system_message=sys_msg, tools=tools, memory=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c9a64",
   "metadata": {},
   "source": [
    "After create the agent, let's do some examples using Replicate to identify the following images:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4304b8ff",
   "metadata": {},
   "source": [
    "![](https://images.pexels.com/photos/2255935/pexels-photo-2255935.jpeg)\n",
    "![](https://www.livemint.com/rf/Image-621x414/LiveMint/Period1/2012/10/01/Photos/Road621.jpg)\n",
    "![](https://media.business-humanrights.org/media/images/16278498935_dac4d8f223_o.2e16d0ba.fill-1000x1000-c50.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51551c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am sorry, but I was unable to process the image and identify the produce due to an internal error with the object detection tool. It appears there's an issue with the linked account for the REPLICATE application. Therefore, I cannot provide the natural language summary, markdown table, or the result image at this time.\n",
      "I am sorry, but I was unable to process the image and identify the objects due to an internal error with the object detection tool. It appears there's an issue with the linked account for the REPLICATE application. Therefore, I cannot provide the natural language summary, markdown table, or the result image at this time.\n",
      "I am sorry, but I was unable to process the image and identify the objects due to an internal error with the object detection tool. It appears there's an issue with the linked account for the REPLICATE application. Therefore, I cannot provide the natural language summary, markdown table, or the result image at this time.\n"
     ]
    }
   ],
   "source": [
    "tasks = (\n",
    "    \"Analyze the vegetable stall and identify all produce, including tomato, onion, cabbage, cucumber, zucchini, carrot, and beet, in this image: https://images.pexels.com/photos/2255935/pexels-photo-2255935.jpeg\",\n",
    "    \"Analyze the busy street scene and identify all vehicles, such as car, bus, and truck, as well as people, in this image: https://www.livemint.com/rf/Image-621x414/LiveMint/Period1/2012/10/01/Photos/Road621.jpg\",\n",
    "    \"Analyze the warehouse scene and identify persons, cardboard boxes, and conveyor belts in this image: https://media.business-humanrights.org/media/images/16278498935_dac4d8f223_o.2e16d0ba.fill-1000x1000-c50.jpg\"\n",
    ")\n",
    "\n",
    "for task in tasks:\n",
    "    response = await agent.astep(task)\n",
    "    print(response.msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41f02d",
   "metadata": {},
   "source": [
    "Finally, we disconnect the MCP toolkit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ddd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "await mcp_toolkit.disconnect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
